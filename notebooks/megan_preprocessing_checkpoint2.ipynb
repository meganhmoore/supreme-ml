{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "337ab19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, Conversation, Utterance, Speaker, FightingWords, download\n",
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7333028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading supreme-1994 to /Users/meganmoore/.convokit/downloads/supreme-1994\n",
      "Downloading supreme-1994 from http://zissou.infosci.cornell.edu/convokit/datasets/supreme-corpus/supreme-1994.zip (8.6MB)... Done\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-1995\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-1996\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-1997\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-1998\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-1999\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2000\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2001\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2002\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2003\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2004\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Downloading supreme-2005 to /Users/meganmoore/.convokit/downloads/supreme-2005\n",
      "Downloading supreme-2005 from http://zissou.infosci.cornell.edu/convokit/datasets/supreme-corpus/supreme-2005.zip (9.4MB)... Done\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Downloading supreme-2010 to /Users/meganmoore/.convokit/downloads/supreme-2010\n",
      "Downloading supreme-2010 from http://zissou.infosci.cornell.edu/convokit/datasets/supreme-corpus/supreme-2010.zip (8.8MB)... Done\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2011\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2012\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2013\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2014\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Dataset already exists at /Users/meganmoore/.convokit/downloads/supreme-2015\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n",
      "Downloading supreme-2016 to /Users/meganmoore/.convokit/downloads/supreme-2016\n",
      "Downloading supreme-2016 from http://zissou.infosci.cornell.edu/convokit/datasets/supreme-corpus/supreme-2016.zip (7.2MB)... Done\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'name'. Overwriting with other Corpus's metadata.\n",
      "\u001b[91mWARNING: \u001b[0mFound conflicting values for Corpus metadata key: 'year'. Overwriting with other Corpus's metadata.\n"
     ]
    }
   ],
   "source": [
    "rehnquist_full_years = [i for i in range(1994,2006)]\n",
    "rehnquist_corpus = None\n",
    "for year in rehnquist_full_years:\n",
    "    corp = Corpus(filename=download(f\"supreme-{year}\"))\n",
    "    if not rehnquist_corpus:\n",
    "        rehnquist_corpus = corp\n",
    "    else:\n",
    "        rehnquist_corpus = Corpus.merge(rehnquist_corpus, corp)\n",
    "\n",
    "roberts_full_years = [i for i in range(2010,2017)]\n",
    "roberts_corpus = None\n",
    "for year in roberts_full_years:\n",
    "    corp = Corpus(filename=download(f\"supreme-{year}\"))\n",
    "    if not roberts_corpus:\n",
    "        roberts_corpus = corp\n",
    "    else:\n",
    "        roberts_corpus = Corpus.merge(roberts_corpus, corp)\n",
    "\n",
    "\n",
    "# Second, we filter out the cases that belong to the previous or the following court\n",
    "\n",
    "with open('../data/cases.json', \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "    begin_date_rehn7 = datetime.strptime('Aug 3, 1994', '%b %d, %Y')\n",
    "    end_date_rehn7 = datetime.strptime('Sep 28, 2005','%b %d, %Y')\n",
    "    begin_date_rob4 = datetime.strptime('Aug 7, 2010', '%b %d, %Y')\n",
    "    end_date_rob4 = datetime.strptime('Feb 13, 2016', '%b %d, %Y')\n",
    "    case_ids_rehn7 = []\n",
    "    case_ids_rob4 = []\n",
    "    for case in data:\n",
    "        str_date = case[\"decided_date\"]\n",
    "        if isinstance(str_date, str):\n",
    "            num_date = datetime.strptime(str_date, '%b %d, %Y')\n",
    "            if num_date >= begin_date_rehn7 and num_date <= end_date_rehn7:\n",
    "                case_ids_rehn7.append(case[\"id\"])\n",
    "            if num_date >= begin_date_rob4 and num_date <= end_date_rob4:\n",
    "                case_ids_rob4.append(case[\"id\"])\n",
    "with open('../data/filtered_cases.json', \"w\") as f2:\n",
    "    json.dump({\"rehn7\": case_ids_rehn7,\"rob4\": case_ids_rob4}, f2, indent=1)\n",
    "\n",
    "rehnquist_corpus = rehnquist_corpus.filter_conversations_by(lambda u: str(u.meta[\"case_id\"]) in case_ids_rehn7)\n",
    "roberts_corpus = roberts_corpus.filter_conversations_by(lambda u: u.meta[\"case_id\"] in case_ids_rob4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159bd9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third, we build a dataframe for each court...\n",
    "\n",
    "cases_df = pd.read_json('../data/cases.json', lines=True)\n",
    "roberts_cases = cases_df.loc[cases_df.loc[:, 'year'].isin(roberts_full_years)]\n",
    "renquist_cases = cases_df.loc[cases_df.loc[:, 'year'].isin(rehnquist_full_years)]\n",
    "\n",
    "\n",
    "# ... and we split each of them into wins and losses\n",
    "\n",
    "rehnquist_convo_df= rehnquist_corpus.get_conversations_dataframe()\n",
    "rehnquist_wins_df = rehnquist_convo_df.loc[rehnquist_convo_df.loc[:, 'meta.win_side'] == 1, :]\n",
    "rehnquist_losses_df = rehnquist_convo_df.loc[rehnquist_convo_df.loc[:, 'meta.win_side'] == 0, :]\n",
    "\n",
    "roberts_convo_df= roberts_corpus.get_conversations_dataframe()\n",
    "roberts_wins_df = roberts_convo_df.loc[roberts_convo_df.loc[:, 'meta.win_side'] == 1, :]\n",
    "roberts_losses_df = roberts_convo_df.loc[roberts_convo_df.loc[:, 'meta.win_side'] == 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e29ea",
   "metadata": {},
   "source": [
    "## Baseline Setting\n",
    "Before beginning the process to create predictions we should establish some baseline values in order to be able to determine if our model performs better than defaulting to the majority. In both courts the win side holds the majority a bit more than 60% of the time. The fact that this is not a perfect 50/50 split between win and lose is not particularly surprising because since the court chooses the cases that it hears, it will likely bias towards cases that it thinks are likely to win. If they believe the case is sure to lose they will likely uphold the decision from the lower court and not choose to hear the case in the Supreme Court."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c2b5a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meta.win_side\n",
       "1.0              543\n",
       "0.0              318\n",
       "2.0                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish baseline probabilities (whatever the majority outcome is for a given court, \n",
    "# what percentage of cases have that outcome)?\n",
    "\n",
    "rehnquist_convo_df.groupby('meta.case_id', as_index=True).agg({'meta.win_side': 'max'}).loc[: 'meta.win_side'].value_counts() # baseline is 543/862 = ~ 63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "543dc892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meta.win_side\n",
       "1                225\n",
       "0                126\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberts_convo_df.groupby('meta.case_id', as_index=True).agg({'meta.win_side': 'max'}).loc[: 'meta.win_side'].value_counts() # baseline is 225/351 = ~ 64%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8ad5b",
   "metadata": {},
   "source": [
    "## Baseline outcomes\n",
    "For the Rehnquist court there are a total of 862 cases, 543 of which won. This means that if we were to predict a win for every case, we would be correct 63% of the time.\n",
    "\n",
    "For the Roberts court there are a total of 351 cases, 225 of which won. This means that if we were to perdict a win for every case, we would be correct 64% of the time. \n",
    "\n",
    "Therefore our model will need to perform at these baselines or better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcd157",
   "metadata": {},
   "source": [
    "## Model Preparation Process\n",
    "### Data Preparation\n",
    "We chose the initial data preparation process based on [this resource](https://developers.google.com/machine-learning/guides/text-classification/step-2-5)\n",
    "N-gram vectorization -> bigram range -> tf-idf count mode -> f_classif scoring -> top 20k feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83a8e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of conversations/utterances to train on and their labels\n",
    "rehnquist_utterances_df= rehnquist_corpus.get_utterances_dataframe()\n",
    "roberts_utterances_df= roberts_corpus.get_utterances_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dc9b7f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>meta.case_id</th>\n",
       "      <th>meta.start_times</th>\n",
       "      <th>meta.stop_times</th>\n",
       "      <th>meta.speaker_type</th>\n",
       "      <th>meta.side</th>\n",
       "      <th>meta.timestamp</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22372__0_000</th>\n",
       "      <td>None</td>\n",
       "      <td>We will hear argument next in Case 09-479, Abb...</td>\n",
       "      <td>j__john_g_roberts_jr</td>\n",
       "      <td>None</td>\n",
       "      <td>22372</td>\n",
       "      <td>2010_09-479</td>\n",
       "      <td>[0.0, 12.808]</td>\n",
       "      <td>[12.808, 13.824]</td>\n",
       "      <td>J</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372__0_001</th>\n",
       "      <td>None</td>\n",
       "      <td>Mr. Chief Justice, and may it please the Court...</td>\n",
       "      <td>david_l_horan</td>\n",
       "      <td>22372__0_000</td>\n",
       "      <td>22372</td>\n",
       "      <td>2010_09-479</td>\n",
       "      <td>[13.824, 17.11, 24.531, 40.391, 56.834, 59.953...</td>\n",
       "      <td>[17.11, 24.531, 40.391, 56.834, 59.953, 77.314...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>13.824</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372__0_002</th>\n",
       "      <td>None</td>\n",
       "      <td>Well, if the text of this is so clear, how is ...</td>\n",
       "      <td>j__samuel_a_alito_jr</td>\n",
       "      <td>22372__0_001</td>\n",
       "      <td>22372</td>\n",
       "      <td>2010_09-479</td>\n",
       "      <td>[89.122]</td>\n",
       "      <td>[99.81]</td>\n",
       "      <td>J</td>\n",
       "      <td>None</td>\n",
       "      <td>89.122</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372__0_003</th>\n",
       "      <td>None</td>\n",
       "      <td>Your Honor, as a judicial matter, I would note...</td>\n",
       "      <td>david_l_horan</td>\n",
       "      <td>22372__0_002</td>\n",
       "      <td>22372</td>\n",
       "      <td>2010_09-479</td>\n",
       "      <td>[99.81]</td>\n",
       "      <td>[104.762]</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>99.81</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22372__0_004</th>\n",
       "      <td>None</td>\n",
       "      <td>But they are not the same, are they?</td>\n",
       "      <td>j__samuel_a_alito_jr</td>\n",
       "      <td>22372__0_003</td>\n",
       "      <td>22372</td>\n",
       "      <td>2010_09-479</td>\n",
       "      <td>[104.762]</td>\n",
       "      <td>[106.797]</td>\n",
       "      <td>J</td>\n",
       "      <td>None</td>\n",
       "      <td>104.762</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                                               text   \n",
       "id                                                                          \n",
       "22372__0_000      None  We will hear argument next in Case 09-479, Abb...  \\\n",
       "22372__0_001      None  Mr. Chief Justice, and may it please the Court...   \n",
       "22372__0_002      None  Well, if the text of this is so clear, how is ...   \n",
       "22372__0_003      None  Your Honor, as a judicial matter, I would note...   \n",
       "22372__0_004      None               But they are not the same, are they?   \n",
       "\n",
       "                           speaker      reply_to conversation_id meta.case_id   \n",
       "id                                                                              \n",
       "22372__0_000  j__john_g_roberts_jr          None           22372  2010_09-479  \\\n",
       "22372__0_001         david_l_horan  22372__0_000           22372  2010_09-479   \n",
       "22372__0_002  j__samuel_a_alito_jr  22372__0_001           22372  2010_09-479   \n",
       "22372__0_003         david_l_horan  22372__0_002           22372  2010_09-479   \n",
       "22372__0_004  j__samuel_a_alito_jr  22372__0_003           22372  2010_09-479   \n",
       "\n",
       "                                               meta.start_times   \n",
       "id                                                                \n",
       "22372__0_000                                      [0.0, 12.808]  \\\n",
       "22372__0_001  [13.824, 17.11, 24.531, 40.391, 56.834, 59.953...   \n",
       "22372__0_002                                           [89.122]   \n",
       "22372__0_003                                            [99.81]   \n",
       "22372__0_004                                          [104.762]   \n",
       "\n",
       "                                                meta.stop_times   \n",
       "id                                                                \n",
       "22372__0_000                                   [12.808, 13.824]  \\\n",
       "22372__0_001  [17.11, 24.531, 40.391, 56.834, 59.953, 77.314...   \n",
       "22372__0_002                                            [99.81]   \n",
       "22372__0_003                                          [104.762]   \n",
       "22372__0_004                                          [106.797]   \n",
       "\n",
       "             meta.speaker_type meta.side meta.timestamp vectors  \n",
       "id                                                               \n",
       "22372__0_000                 J      None            0.0      []  \n",
       "22372__0_001                 A         1         13.824      []  \n",
       "22372__0_002                 J      None         89.122      []  \n",
       "22372__0_003                 A         1          99.81      []  \n",
       "22372__0_004                 J      None        104.762      []  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberts_utterances_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a90d57a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 5)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rehnquist_convo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "973e337d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, None], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rehnquist_convo_df.loc[:, 'meta.win_side'].unique() # for some reason there are some unexpected values in the rehnquist win side cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb1ff7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rehnquist_convo_df.drop(rehnquist_convo_df[rehnquist_convo_df.loc[:, 'meta.win_side'] == 2].index, inplace=True)\n",
    "rehnquist_convo_df.drop(rehnquist_convo_df[rehnquist_convo_df.loc[:, 'meta.win_side'].isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b7a3abdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864, 5)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rehnquist_convo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "868baad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberts_utt_win_df = pd.merge(roberts_utterances_df, roberts_convo_df.loc[:, ['meta.case_id', 'meta.win_side']], left_on = 'meta.case_id', right_on = 'meta.case_id', how='left')\n",
    "rehnquist_utt_win_df = pd.merge(rehnquist_utterances_df, rehnquist_convo_df.loc[:, ['meta.case_id', 'meta.win_side']], left_on = 'meta.case_id', right_on = 'meta.case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ad51a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rehnquist_utt_win_df.loc[rehnquist_utt_win_df.loc[:, 'meta.win_side'].isna(), 'meta.case_id'].unique()\n",
    "rehnquist_utt_win_df.drop(rehnquist_utt_win_df[rehnquist_utt_win_df.loc[:, 'meta.win_side'].isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8629b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO train test split and stratify making sure that there is balance of justices and petitioners speaking in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "12c069df",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberts_train, roberts_valid = train_test_split(roberts_utt_win_df, train_size=0.8)\n",
    "rehnquist_train, rehnquist_valid = train_test_split(rehnquist_utt_win_df, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fbb3ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberts_utterance_vect_train = roberts_train.loc[:, 'text']\n",
    "roberts_label_vect_train = roberts_train.loc[:, 'meta.win_side'].astype(float).to_numpy() #sklearn expects a numpy array for the labels\n",
    "roberts_utterance_vect_valid = roberts_valid.loc[:, 'text']\n",
    "roberts_label_vect_valid = roberts_valid.loc[:, 'meta.win_side'].astype(float).to_numpy()\n",
    "\n",
    "rehnquist_utterance_vect_train = rehnquist_train.loc[:, 'text']\n",
    "rehnquist_label_vect_train = rehnquist_train.loc[:, 'meta.win_side'].astype(float).to_numpy() #sklearn expects a numpy array for the labels\n",
    "rehnquist_utterance_vect_valid = rehnquist_valid.loc[:, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd30f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization parameters\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text (using unigrams and bigrams).\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 2000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cd45c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "        val_texts: list, validation text strings.\n",
    "\n",
    "    # Returns\n",
    "        x_train, x_val: vectorized training and validation texts\n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            'dtype': 'int32',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train).astype('float32')\n",
    "    x_val = selector.transform(x_val).astype('float32')\n",
    "    \n",
    "    \n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "660dc729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meganmoore/miniconda3/envs/supreme-ml/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "roberts_vect_train, roberts_vect_valid = ngram_vectorize(roberts_utterance_vect_train, roberts_label_vect_train, roberts_utterance_vect_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1feba7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meganmoore/miniconda3/envs/supreme-ml/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rehnquist_vect_train, rehnquist_vect_valid = ngram_vectorize(rehnquist_utterance_vect_train, rehnquist_label_vect_train, rehnquist_utterance_vect_valid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9c55e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17383x20000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 294710 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberts_vect_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d302b22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<180746x20000 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1695472 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rehnquist_vect_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "670d4f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meganmoore/miniconda3/envs/supreme-ml/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "roberts_vect_train, roberts_vect_valid= ngram_vectorize(roberts_utterance_vect_train, roberts_label_vect_train, roberts_utterance_vect_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c6509927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meganmoore/miniconda3/envs/supreme-ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "jlg = LogisticRegression().fit(roberts_vect_train, roberts_label_vect_train)\n",
    "predictions = jlg.predict(roberts_vect_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e9bc3355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 20000,\n",
       " 'score_func': <function sklearn.feature_selection._univariate_selection.f_classif(X, y)>}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d0cb70d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7044238623942932"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(roberts_label_vect_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "087a1903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e111ebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberts_label_vect_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fe462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
